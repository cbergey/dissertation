---
output            : 
  pdf_document: 
    template: thesis_CB.tex
    keep_tex: true
    pandoc_args: ["--top-level-division=chapter"]
    
bibliography      : references.bib
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = '!tb', echo = FALSE, cache = TRUE, 
                      warning = FALSE, message = FALSE, 
                      sanitize = TRUE, fig.path='figs/', fig.width = 6,
                      fig.height = 3)
set.seed(42)
options(digits=3, dplyr.summarise.inform = FALSE)
```

```{r libraries, cache = FALSE}
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(tidyverse)
library(lme4)
library(broom)
library(broom.mixed)
#library(ggpubr)
library(here)
library(nnet)
library(english)
library(weights)
library(scales)
library(ggthemes)
library(papaja)
library(gridExtra)
library(glue)
library(directlabels)
library(tidyboot)
library(lmerTest)
library(knitr)
library(rwebppl)
library(ggridges)
logit <- function(x) {log(x/(1-x))}
```

```{r set-theme, cache = FALSE}
theme_set(theme_few(base_size = 10) + theme(legend.position = "none"))
```

```{r make-text-vars}
make_text_vars <- function(df, term_name, term_filter = NULL) {
  if(!is.null(term_filter)) {
    filtered_df <- df %>%
      filter(term == term_filter) 
  } else{
    filtered_df <- df
  }
    
  walk(c("estimate", "statistic", "p.value"), 
      ~assign(glue("{term_name}_{.x}"), 
              filtered_df %>% pull(!!.x), 
         envir = globalenv()))
}
```

# Introduction {-}

An utterance can say much more about the world than its literal interpretation might suggest. For instance, if you hear a colleague say "We should hire a female professor," you might infer something about the speaker's goals, the makeup of a department, or even the biases of a field—none of which is literally stated. These inferences depend on recognition that a speaker's intended meaning can differ from the literal meaning of their utterance, and the process of deriving this intended meaning is called *pragmatics*. Frameworks for understanding pragmatic inference posit that speakers tend to follow general principles of conversation—for instance, that they tend to be relevant, brief, and otherwise helpfully informative [@grice1975logic; @sperber1986relevance; @clark_pragmatics_1990]. When a speaker deviates from these principles, a listener can reason about the alternative utterances the speaker might have said and infer some intended meaning that goes beyond the literal meaning of their utterance.

Beyond enriching the interpretation of utterances whose literal meaning is known, pragmatic inference is a potentially powerful mechanism for learning about new words and concepts. People can learn the meanings of words by tracking associations between word use and present objects alone [@yu2007], but reasoning about a speaker's intended meaning---not just relating the words they say to objects in the environment---may support more rapid and more accurate learning [@frank2009]. For example, @akhtar_role_1996 showed that young children can infer the meaning of a new word by using the principle that people tend to remark on things that are new and interesting to them. In this study, an experimenter leaves the room and a new toy emerges in her absence; once she comes back, the toy is familiar to the child but not to the experimenter. When she uses a novel name, "gazzer," the child can infer that the word refers to the toy that is novel to the experimenter, and not to other toys the experimenter had already seen. Experiments with adults show that they too can use general principles of informativeness to infer a novel referent's name [@frank2014].

One potential pragmatic tool for learning about referents is contrastive inference from description. To the extent that communicators strive to be minimal and informative, description should discriminate between the referent and some relevant contrasting set. This contrastive inference is fairly obvious from some types of description, such as some postnominal modifiers: "The door with the lock" clearly implies a contrasting door without one [@nietal]. The degree of contrast implied by more common descriptive forms, such as prenominal adjectives in English, is less clear: speakers do not always use prenominal adjectives minimally, often describing more than is needed to establish reference [@engelhardt_over-specified_2011; @mangold_informativeness_1988; @pechmann_incremental_1989]. Nevertheless, @sedivy_achieving_1999 showed that people can use these inferences to resolve referential ambiguity in familiar contexts. When asked to "Pick up the tall cup," people directed their attention more quickly to the target when a short cup was present, and did so in the period before they heard the word "cup." Because the speaker would not have needed to specify "tall" unless it was informative, listeners were able to use the adjective to direct their attention to a tall object with a shorter counterpart. Subsequent work using similar tasks has corroborated that people can use contrastive inferences to direct their attention among familiar referents [@sedivy_pragmatic_2003; @aparicio2016processing; @ryskin2019information].

But what if you didn't know the meaning of the key words in someone's utterance---could you use the same kind of contrastive inferences to learn about new words and categories? Suppose a friend asks you to "Pass the tall dax." Intuitively, your friend must have said the word "tall" for a reason. One possibility is that your friend wants to distinguish the dax they want from another dax they do not. In this case, you might look around the room for two similar things that vary in height, and hand the taller one to them. If, alternatively, you only see one object around whose name you don't know, you might draw a different inference: this dax might be a particularly tall dax. In this case, you might think your friend used the word "tall" for a different reason--not to distinguish the dax they want from other daxes around you, but to distinguish the dax they want from other daxes in the world. This would be consistent with data from production studies, in which people tend to describe atypical features more than they describe typical ones [@mitchell_2013; @westerbeek2015; @rubio-fernandez_how_2016]. For instance, people almost always say "blue banana" to refer to a blue banana, but almost never say "yellow banana" to refer to a yellow one. In each of these cases---when distinguishing the dax from other referents nearby, or from daxes in general---you would have used a pragmatic inference to learn something new about the category of daxes.

This dissertation will explore the ways in which people can learn about new words and categories from contrastive inference, with an eye toward understanding how contrastive inference could help children learn about language and the world it describes. To set the stage for understanding how listeners use contrastive inference, we first need to establish that speakers use adjectives in informative ways. 

In Chapter 1, we investigate whether people tend to use adjectives to remark on the atypical features (e.g., "the purple carrot") rather than the typical features (e.g., "the [orange] carrot") of things. In a corpus study of caregivers' speech, we show that caregivers tend to mention atypical rather than typical features of things when speaking to their children. We also show that adults speaking to other adults in naturalistic contexts tend to remark on atypical features rather than typical ones, extending findings from reference game tasks in the lab [@mitchell_2013; @westerbeek2015; @rubio-fernandez_how_2016]. Finally, we show that children's own speech mentions atypical more than typical features, and discuss the implications of this finding for our understanding of children's pragmatic competence.

Given that speech emphasizes atypical features, learning about typicality from language may not be straightforward. In an analysis using language models, we examine whether it is possible to learn about the typical features of things using the statistical patterns within language alone. To do this, we examine whether three language models (word2vec, BERT, and GPT-3) capture typicality relationships between nouns and adjectives. We find that word2vec and BERT do not represent typicality well: likely because they use associative methods to represent word meaning and their input tends to highlight atypical features, these models represent the relationship between nouns and adjectives poorly. However, GPT-3, a larger model trained on much more language than children have access to, captures noun-adjective typicality fairly accurately. We discuss implications for children's word learning as well as for language modeling. 

In Chapter 2, we establish that adults can use contrastive inferences to learn about a new category's feature distribution. People use adjectives for multiple communicative purposes: in some cases, an adjective is needed to pick out one object among others in the immediate environment (e.g., "the tall cup" contrasts with a nearby shorter cup, but is not especially tall); in others, it marks atypicality (e.g., "the tall cup" is taller than most cups in general). In this chapter, we use two experiments with adults to show that people can use contrastive inferences to learn about a new category's feature distribution. People observe instances of novel categories and hear them described (e.g., "Pass me the [green] toma"), and then judge the prevalence of the relevant feature (e.g., how common it is for tomas to be green). People infer that mentioned features are less prevalent than unmentioned ones, and do so even when the feature had to be mentioned to establish reference. We use a model in the Rational Speech Act (RSA) framework to capture people's judgments, finding that their judgments are consistent with graded consideration of both reference and conveying typicality as purposes of using an adjective. 

In Chapter 3, we present a preliminary study of children's own contrastive inferences. We test whether children infer that, for example, mentioning that a certain object is tall, blue or spotted implies that other group members are less likely to have those features. However, testing children in this kind of task presents a key difficulty: young children often struggle with the kinds of scales we use to ask adults about typicality. Our study therefore has two goals: both to examine whether 5- to 6-year-old children can sensibly report typicality on a scale from *few* to *almost all*, and to gather preliminary evidence about their contrastive inferences. We find that though about half of children in this age range struggle with this measure, children who do understand the measure make judgments in the direction of contrastive inference. We discuss the implications of this kind of inference for children's learning given the descriptions they hear from caregivers, and the potential unintended consequences of remarking on individuals' traits for children's learning. 

# People talk more about atypical than typical features of things

```{r child = "diss_sections/chapter_1/ch1.Rmd"}
```

# How adults use contrastive inference to learn about new categories

```{r child = "diss_sections/chapter_2/experiment2.Rmd"}
```

```{r child = "diss_sections/chapter_2/experiment3.Rmd"}
```

## General Discussion

When we think about what someone is trying to communicate to us, we go far beyond the literal meanings of the words they say: we make pragmatic inferences about why they chose those particular words rather than other words they could have used instead. In most work on pragmatic reasoning, speakers and listeners share the same knowledge of language, and the question of interest is whether listeners can use their knowledge of language to learn something about the unknown state of the world. Here we focus on an even more challenging problem: Can pragmatic inference be used to learn about language and the world simultaneously?

In two experiments, we showed that people infer that a noted feature is atypical of the object being referred to. Critically, people infer that the described feature is atypical even when the descriptor is helpful for referential disambiguation. Why do people think that the mentioned feature is atypical even when its mention is helpful for referential disambiguation? If people use language for multiple goals—for example, both for reference and for description—then listeners should reason jointly about all of the possible reasons why speakers could have used a word. To determine what rational listeners would do in this circumstance, we developed an extension of the Rational Speech Act Framework that reasons both about reference and about the typical features of categories to which objects belong. The behavior of this model was closely aligned to the behavior we observed in people. Because rational inference is probabilistic rather than deterministic, the trade-off in the model is slight: descriptors still lead to atypicality inferences even when they are helpful for referential disambiguation. This work thus adds to the growing body of work extending the Rational Speech Act framework from reasoning about just reference to reasoning about other goals as well, such as inferring that speech is hyperbolic, inferring when speakers are being polite rather than truthful, and learning new words in ambiguous contexts [@goodman2016; @yoon2020; @kao2014; @frank2014; @bohn_how_2021; @bohn_predicting_2022].

In considering how people may integrate inferences about typicality and about reference, we raised two broad possibilities: (1) a *reference-first view*, whereby if an adjective was necessary for reference it would block an inference of atypicality completely, and (2) a *probabilistic weighing view*, whereby the goals of being informative with respect to reference and with respect to the category would trade off in a graded way. That is, we aimed to test whether there was a strong trade-off or a weak trade-off. People's behavior in our tasks is inconsistent with the reference-first view: inferences of atypicality were not blocked when an adjective was necessary for reference. On the other hand, our model implements the latter view and fits the data well, but we do not find significant evidence of a trade-off in our statistical tests of people's responses: the data are also compatible with there being no trade-off whatsoever. 

Our experiments use a particular kind of task context: alien fruits, spoken about by alien interlocutors. Would these effects generalize beyond these particular items, and this particular task? It is possible that people hold expectations about how the features of fruit are distributed—for instance, that they have stereotypical colors. These overhypotheses about how basic-level categories' features are distributed within a superordinate category [@kemp_learning_2007] may make people's inferences about fruit different from their inferences about other superordinate categories. More broadly, people may make different kinds of inferences in more naturalistic communicative settings. In our task, people were asked to make several typicality judgments, which may have encouraged them to focus on how the aliens' utterances could help them learn about the world rather than focusing on other communicative goals such as reference. It is possible that people's inferences would reflect a clear tradeoff between reference and communicating atypicality if reference was a more salient communicative goal in the task. Further, it may be easier to attribute nuanced communicative goals to *people* talking about plausibly real things, rather than to alien characters. So, though we find people do use pragmatic inferences to learn about new categories in these artificial tasks, these inferences may play out differently in more naturalistic contexts with more communicative goals plausibly in play.

In Chapter 1, we established that people tend to mention atypical rather than typical features. In this chapter, we showed that adults make appropriate pragmatic inferences given how speakers describe: they infer that a mentioned feature is likely to be less typical of the mentioned category. However, the ability to learn about new categories using contrastive inference most obviously serves budding language learners---children. To fully appreciate the potential of these inferences to allow people to learn about the world, we must study their development, which we will turn to in Chapter 3.

# How children use contrastive inference to learn about new categories

```{r child = "diss_sections/chapter_3/ch3.Rmd"}
```

# Conclusion {-}

This dissertation examines how speakers selectively describe remarkable features and how listeners use this selective description to learn more about the world. In doing so, it inverts the framework that has positioned pragmatic inference as augmenting literal meaning that is already known, instead considering how people can use pragmatics to learn more about the semantics of unfamiliar things. 

To understand how people use description to learn about the world, we first must know how description is used. Chapter 1 illustrates how caregivers use description in speaking to children, as well as establishing how adults use description when speaking to other adults and how children themselves use description. We find that parents predominantly mention atypical rather than typical features when speaking to children, as do adults when speaking to other adults. 

We also examined how children themselves use description, and found that they mostly talk about the atypical features of things. There are several language-generating processes that may explain children's use of description. One possibility is that children understand that description is used to draw a distinction between the described thing and some relevant alternatives—that they are using description informatively to highlight atypicality. Another possibility is that children are broadly reflecting the distribution of adjective-noun usage in their parents' speech, simply by producing the kinds of adjective-noun pairs they have heard before. A third is that their pattern of description is largely explained by local mimicry---that children are directly repeating back adjectives and nouns their parents used recently in conversation. More focused corpus analyses, as well as experiments eliciting children's adjective production, are necessary to distinguish between these possibilities.

The pattern of description we find in parents' speech to children is consistent with the idea that people use language informatively with relation to background knowledge of the world, rather than giving veridical running commentary on the world's features. This finding raises questions about how children use description to learn, given that so many accounts of language learning rest on children forming associations among co-occurring words, features, and concepts. To test what kind of typicality information is derivable from language alone, we investigated whether language models that use associative learning among words can extract typical feature information from language. We find that simpler distributional semantics models do poorly in distinguishing between the typical and atypical features of nouns, with implications both for associative accounts of children's language learning and for language modeling. However, a large language model with a more complex architecture and access to more and different language input than children receive---GPT-3---was able to capture adjective-noun typicality fairly well. Overall, our findings highlight the complexity of learning about the world from language that describes it selectively.

However, perhaps people---unlike simpler associative language models---know that language is used to selectively remark on the world, and can use this fact to learn about the unfamiliar. In Chapter 2, we investigated how adults make inferences about novel object categories, and found that they can use description to infer that a described feature is atypical. Further, even when description may have been used for another purpose---to establish reference---people make inferences about typicality. We find that a model that considers the utility of utterances with respect to reference and typicality captures people's inferences. Much prior work has only considered the use of description in distinguishing between present referents [@pechmann_incremental_1989;  @engelhardt_over-specified_2011; @mangold_informativeness_1988], and even work that has incorporated typicality has focused on reference as the primary goal of description [@sedivy_pragmatic_2003; @mitchell_2013; @westerbeek2015; @rubio-fernandez_how_2016]. Our findings emphasize that conveying typicality is likely a central factor in referring, and inferences about typicality are not secondary to or blocked by the purpose of establishing reference. Further, though pragmatics is generally conceived of as a layer of meaning that only emerges on top of a more stable semantics, our findings demonstrate the reverse: when semantic meaning is uncertain, people can use pragmatics to resolve it.

The ability to exploit description to learn more about the world than one has observed directly is most useful to people who are still rapidly learning---children. In Chapter 3, we investigated how 5- to 6-year-old children make contrastive inferences about typicality. The results of our preliminary experiment show that it is difficult to elicit graded typicality judgments from children. However, children who understand our typicality measure do not make associative inferences in this task; rather, we find preliminary evidence that these children directionally make contrastive inferences. Taken together with evidence from our corpus analysis, this preliminary study suggests that by the age of 5 or 6 children are *not* making associative inferences about the atypical adjective-noun pairs they hear, and may be making contrastive inferences instead. However, further work with better measures is necessary to confirm this finding and examine how younger children interpret the description they hear.

The core computation in pragmatic inference is reasoning about alternatives---things the speaker could have said and did not. Given that others are reasoning about these alternatives, no choice is neutral. In the studies in Chapter 2, for instance, using an adjective in referring to an object led people to infer that the feature described by that adjective was less typical than if it had not been mentioned. But, conversely, *not* using an adjective led them to think that the feature was more typical than if they could not understand the meaning of the utterance at all---all communicative choices leak one's beliefs about the world. This has implications not only for learning about novel concrete objects, as people did here, but for learning about less directly accessible entities such as abstract concepts and social groups. These inferences can be framed positively, as ways for learners to extract additional knowledge that was not directly conveyed, but can also spread beliefs that the speaker does not intend. The principle that people speak informatively is simple, but it holds unintuitive consequences---among speakers and listeners, humans and machines, adults and children---for describing and learning about the world.

\newpage
# References
